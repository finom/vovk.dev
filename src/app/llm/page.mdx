# LLM Completions

## JSON Lines

LLM completions can be streamed using the [JSON Lines](https://jsonlines.org/) format, which is a convenient way to send a stream of JSON objects over HTTP. On the back-end, streaming is implemented with [Generator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Generator) functions, which allow you to yield data as it becomes available. For the OpenAI API (as well as for other completion APIs), this can be done by delegating the iterable using the `yield*` syntax.

Read more about [JSONLines Response](/controller/jsonlines) and [Controllers](/controllers).

```ts filename="src/modules/llm/LlmController.ts"
import { post, prefix, operation, type VovkRequest } from 'vovk';
import OpenAI from 'openai';

@prefix('openai')
export default class OpenAiController {
  @operation({
    summary: 'Create a chat completion',
  })
  @post('chat')
  static async *createChatCompletion(
    req: VovkRequest<{ messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] }>
  ) {
    const { messages } = await req.json();
    const openai = new OpenAI();

    yield* await openai.chat.completions.create({
      messages,
      model: 'gpt-5-nano',
      stream: true,
    });
  }
}
```

On the client side, you can use a [disposable](https://github.com/tc39/proposal-explicit-resource-management) [async iterator](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/AsyncIterator) to read the stream:

```ts
// ...
using completion = await OpenAiRPC.createChatCompletion({
  body: { messages: [...messages, userMessage] },
});

for await (const part of completion) {
  // ...
}
```

See [live example](https://vovk-examples.vercel.app/openai) for more details.

## Vercel AI SDK

> The AI SDK is the TypeScript toolkit designed to help developers build AI-powered applications with React, Next.js, Vue, Svelte, Node.js, and more. Read more about the [Vercel AI SDK](https://sdk.vercel.ai/docs/introduction).

Vovk.ts supports every built-in feature of Next.js and, as a result, can be used with the Vercel AI SDK by returning a `Response` object from the `toDataStreamResponse` function with no additional tricks.

```ts filename="src/modules/ai-sdk/AiSdkController.ts"
import { post, prefix, operation, type VovkRequest } from 'vovk';
import { streamText, convertToModelMessages, type UIMessage } from 'ai';
import { openai } from '@ai-sdk/openai';

@prefix('ai-sdk')
export default class AiSdkController {
  @operation({
    summary: 'Vercel AI SDK',
  })
  @post('chat')
  static async chat(req: VovkRequest<{ messages: UIMessage[] }>) {
    const { messages } = await req.json();

    return streamText({
      model: openai('gpt-5-nano'),
      system: 'You are a helpful assistant.',
      messages: convertToModelMessages(messages),
    }).toUIMessageStreamResponse();
  }
}
```

On the client side, you can use the [@ai-sdk/react](https://www.npmjs.com/package/@ai-sdk/react) package to interact with the endpoint and build a chat interface as per the original SDK design.

```tsx
'use client';
import { useChat } from '@ai-sdk/react';
import { DefaultChatTransport } from 'ai';
import { useState } from 'react';

export default function Page() {
  const [input, setInput] = useState('');

  const { messages, sendMessage, error, status } = useChat({
    transport: new DefaultChatTransport({
      api: '/api/ai-sdk/chat',
    }),
  });

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (input.trim()) {
      sendMessage({ text: input });
      setInput('');
    }
  };

  return (
    <form onSubmit={handleSubmit}>
      {messages.map((message) => (
        <div key={message.id}>
          {message.role === 'assistant' ? 'ü§ñ' : 'üë§'}{' '}
          {message.parts.map((part, partIndex) => (
            <span key={partIndex}>{part.type === 'text' ? part.text : ''}</span>
          ))}
        </div>
      ))}
      {error && <div>‚ùå {error.message}</div>}
      <div className="input-group">
        <input type="text" placeholder="Send a message..." value={input} onChange={(e) => setInput(e.target.value)} />
        <button>Send</button>
      </div>
    </form>
  );
}
```


See [live example](https://vovk-examples.vercel.app/ai-sdk) for more details.
