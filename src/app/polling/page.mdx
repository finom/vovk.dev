import GithubFiles from '@/components/GithubFiles';
import { PollExample } from '../../components/vovk-examples';

TODO: deletions need to be explicit

# Realtime polling (experimental)

## The goal

- Make the UI update automatically when the data is changed by other users or third-party services
- Use only HTTP protocol (no WebSockets, no SSE) to ensure compatibility with any hosting provider

##  Introduction

In the [previous article](/realtime-ui), we covered how to use the OpenAPI Realtime API to deliver instant UI updates while the user interacts with the app. The LLM functions created with `createLLMTools` ran in the browser, where the AI performed HTTP requests to the server using RPC modules.

On this page, we explain how to use database polling to receive updates triggered by other users or third-party services (such as [MCP](/mcp)), keeping the UI in sync with the database. To ensure the app can be deployed to any hosting provider, we avoid non-HTTP protocols such as WebSockets and instead use HTTP polling powered by [JSONLines](/controller/jsonlines).

The component below demonstrates a simple polling example that receives incremental updates from the server every second (see "Network" tab at dev tools). After 10 updates, the server closes the connection, and the client reconnects automatically. We can use the same approach to receive database updates in real time, by having the server send updates whenever the database changes.

<div className="example">
<PollExample />
[View on examples.vovk.dev »](https://examples.vovk.dev/polling)
</div>

## Redis DB as event bus

While we could poll the main Postgres database for changes, that approach is inefficient. Instead, we use Redis as an event bus. Whenever the main database changes, we write a small event to Redis. Our polling service reads these events every second and relays them to clients with the app open.

Because we use [Prisma](https://www.prisma.io/) as our ORM, we rely on [Prisma Extensions](https://www.prisma.io/docs/orm/prisma-client/client-extensions) to hook into database operations and write events to Redis. This is where the `DatabaseService` mentioned in the [previous article](/realtime-ui) comes into play.

<GithubFiles paths={['src/modules/database/DatabaseService.ts']} repo="vovk-kanban-demo" cutLines={[3, [7, 13]]} highlightLines={[19, 95]} />

- The `getClient` method calls `DatabaseEventsService.beginEmitting(){:ts}` to start emitting events. `beginEmitting` runs a `setInterval` that connects to Redis and periodically checks for new events. When a new event is found, it emits it via [mitt](https://npmjs.com/package/mitt).
- `prisma.$extends` hooks into all Prisma model operations, determines whether an operation modifies data, and if so calls `await DatabaseEventsService.createChanges([change]){:ts}` to persist a change entry in Redis. The change captures creates, updates, and deletions:

```ts
export type DBChange = {
  id: string;
  entityType: EntityType;
  date: string;
  type: "create" | "update" | "delete";
};
```

The `date` field indicates when the change occurred.

- For `create` and `update` operations, it uses the `updatedAt` DB field (Important: all write operations must set this field).
- For `delete` operations, it uses the current time.

The `delete` operation also adds an `__isDeleted` property. The front end checks this property to hide the deleted entity by setting `enumerable: false` on the entity registry item (see the [previous article](/realtime-ui)).

Operations like `find...` and `count` do not trigger changes and are passed through as-is.

In addition to `beginEmitting` and `createChanges`, `DatabaseEventsService` provides a `connect` method and an `emitter` (a `mitt` instance). These are used by the polling service (`DatabasePollService`, discussed next) to be notified about new events.

<GithubFiles paths={['src/modules/database/DatabaseEventsService.ts']} repo="vovk-kanban-demo" />

## Polling controller and service

With Redis change entries and the change emitter in place, we can implement a polling endpoint that streams updates to clients in real time. The `DatabasePollController` exposes a single [JSONLines](/controller/jsonlines) endpoint, and `DatabasePollService` uses a [JSONLinesResponse](/controller/jsonlines#jsonlinesresponse) instance (received from the controller) to send data to clients. The service closes the connection safely after 30 seconds, so clients should reconnect.

<GithubFiles paths={['src/modules/database/DatabasePollService.ts', 'src/modules/database/DatabasePollController.ts']} repo="vovk-kanban-demo"  />

- When a `delete` DB change is emitted via `DatabaseEventsService.emitter`, the service sends an event with `id`, `entityType`, and `__isDeleted: true`. The front end uses `__isDeleted` to hide the entity by making it non-enumerable in the registry.
- When an `update` or `create` change is emitted, the service fetches the full entity from Postgres (since Redis stores only metadata) and sends it to clients.

## Client-side logic

On the client side (for example, in a React component), call `DatabasePollRPC.poll()` to receive a stream of database events. As with any [JSONLines](/controller/jsonlines) RPC method, it returns an async iterable that you can consume in a `for await` loop. Because the server may close the connection or a network error may occur, wrap the logic in a retry loop and avoid reconnecting on `AbortError`. Since the [fetcher](/imports#fetcher) is already [configured](/realtime-ui#fetcher), the loop body can be empty—you do not need to handle data manually.

Front-end code, besides the polling logic, also includes on/off toggle state saved to `localStorage`, so the user can enable or disable polling as needed.

```tsx
const [isPollingEnabled, setIsPollingEnabled] = useState(false);
const pollingAbortControllerRef = useRef<AbortController | null>(null);

useEffect(() => {
  const isEnabled = localStorage.getItem("isPollingEnabled");
  setIsPollingEnabled(isEnabled === "true");
}, []);

useEffect(() => {
  localStorage.setItem("isPollingEnabled", isPollingEnabled.toString());
  async function poll(retries = 0) {
    if (!isPollingEnabled) {
      pollingAbortControllerRef.current?.abort();
      return;
    }
    try {
      while (true) {
        console.log("START POLLING");
        const iterable = await DatabasePollRPC.poll();
        pollingAbortControllerRef.current = iterable.abortController;

        for await (const iteration of iterable) {
          console.log("New DB update:", iteration);
        }
      }
    } catch (error) {
      if (
        retries < 5 &&
        (error as Error & { cause?: Error }).cause?.name !== "AbortError"
      ) {
        console.error("Polling failed, retrying...", error);
        await new Promise((resolve) => setTimeout(resolve, 2000));
        return poll(retries + 1);
      }
    }
  }

  void poll();

  return () => {
    pollingAbortControllerRef.current?.abort();
  };
}, [isPollingEnabled]);
```

## Bonus: Telegram bot (unstable)

As an example of a third-party source of database changes, see the [TelegramService](https://github.com/vovk-kanban-demo/src/modules/telegram/TelegramService.ts) and the accompanying [TelegramController](https://github.com/vovk-kanban-demo/src/modules/telegram/TelegramController.ts). It accepts text or voice messages, performs voice-to-text transcription if needed using the OpenAI Whisper API, and uses the same `createLLMTools` function on the server:

```ts
const { tools } = createLLMTools({
  modules: {
    UserController,
    TaskController,
  },
});
```

The Telegram API library is implemented with [OpenAPI Mixins](/codegen) and used as a `TelegramAPI` module to call Telegram API methods.

```ts filename="vovk.config.mjs"
// @ts-check
/** @type {import('vovk').VovkConfig} */
const config = {
  // ...
  outputConfig: {
    // ...
    segments: {
      telegram: {
        openAPIMixin: {
          source: {
            url: "https://raw.githubusercontent.com/sys-001/telegram-bot-api-versions/refs/heads/main/files/openapi/yaml/v183.yaml",
            fallback: ".openapi-cache/telegram.yaml",
          },
          getModuleName: "TelegramAPI",
          getMethodName: ({ path }) => path.replace(/^\//, ""),
          errorMessageKey: "description",
        },
      },
    },
  },
};

export default config;
```

The `TelegramService` class handles interaction with the Telegram API and generates AI responses using the Vercel AI SDK.

```ts filename="src/modules/telegram/TelegramService.ts"
import OpenAI from "openai";
import { TelegramAPI } from "vovk-client";

const openai = new OpenAI();

export default class TelegramService {
  static get apiRoot() {
    const TELEGRAM_BOT_TOKEN = process.env.TELEGRAM_BOT_TOKEN;
    if (!TELEGRAM_BOT_TOKEN) {
      throw new Error("Missing TELEGRAM_BOT_TOKEN environment variable");
    }
    return `https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}`;
  }

  // ...

  private static async generateAIResponse(
    chatId: number,
    userMessage: string,
    systemPrompt: string,
  ): Promise<{ botResponse: string; messages: ModelMessage[] }> {
    // Get chat history
    const history = await this.getChatHistory(chatId);
    const messages = [
      ...this.formatHistoryForVercelAI(history),
      { role: "user", content: userMessage } as const,
    ];
    const { tools } = createLLMTools({
      modules: {
        UserController,
        TaskController,
      },
    });
  
    // Generate a response using Vercel AI SDK
    const { text } = await generateText({
      model: vercelOpenAI("gpt-5"),
      system: systemPrompt,
      messages,
      stopWhen: stepCountIs(16),
      tools: {
        ...Object.fromEntries(
          tools.map(({ name, execute, description, parameters }) => [
            name,
            tool<KnownAny, KnownAny>({
              execute,
              description,
              inputSchema: jsonSchema(parameters as KnownAny),
            }),
          ]),
        ),
      },
    });

    const botResponse = text || "I couldn't generate a response.";

    // Add user message to history
    await this.addToHistory(chatId, "user", userMessage);
    // Add assistant response to history
    await this.addToHistory(chatId, "assistant", botResponse);

    messages.push({
      role: "assistant",
      content: botResponse,
    });

    return { botResponse, messages };
  }

  private static async sendTextMessage(
    chatId: number,
    text: string,
  ): Promise<void> {
    await TelegramAPI.sendMessage({
      body: {
        chat_id: chatId,
        text: text,
        parse_mode: "html",
      },
      apiRoot: this.apiRoot,
    });
  }

  private static async sendVoiceMessage(
    chatId: number,
    text: string,
  ): Promise<void> {
    try {
      // Generate speech from text using OpenAI TTS
      const speechResponse = await openai.audio.speech.create({
        model: "tts-1",
        voice: "alloy",
        input: text,
        response_format: "opus",
      });

      // Convert the response to a Buffer
      const voiceBuffer = Buffer.from(await speechResponse.arrayBuffer());

      const formData = new FormData();
      formData.append("chat_id", String(chatId));
      formData.append(
        "voice",
        new Blob([voiceBuffer], { type: "audio/ogg" }),
        "voice.ogg",
      );

      // Send the voice message
      await TelegramAPI.sendVoice({
        body: formData,
        apiRoot: this.apiRoot,
      });
    } catch (error) {
      console.error("Error generating voice message:", error);
      // Fallback to text message if voice generation fails
      await this.sendTextMessage(chatId, text);
    }
  }

  // ...
}
```

