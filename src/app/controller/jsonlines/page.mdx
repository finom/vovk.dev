import { JSONLinesExample } from '../../../components/vovk-examples';
import { Suspense } from 'react';

# JSON Lines streaming

<div className="example">
  <JSONLinesExample />
</div>


Vovk.ts includes first class support for [JSONLines](https://jsonlines.org/) format, which is a convenient way to implement "one request - many responses". It's perfect for LLM completions, but also opens up a new field for experiments, such as [progressive responses](/controller/progressive) and [polling](/guides/polling). JSONLines is another kind of output that uses `iteration` validation field and produces `application/jsonl` content-type if client-side sends `Accept: application/jsonl` header. If the `Accepts` header doesn't include `application/jsonl`, the output is returned as `text/plain` to be available when the endpoint URL is opened directly in the browser.

```ts
import { z } from 'zod';
import { prefix, post, type VovkIteration } from 'vovk';
import { withZod } from 'vovk-zod';

@prefix('stream')
export default class StreamController {
  @post('completions')
  static getJSONLines = withZod({
    // ...
    iteration: z.object({
      message: z.string(),
    }),
    async handle() {
      const tokens: VovkIteration<typeof StreamController.getJSONLines>[] = [
        { message: 'Hello,' },
        { message: ' World' },
        { message: ' from' },
        { message: ' Stream' },
        { message: '!' },
      ];

      for (const token of tokens) {
        await new Promise((resolve) => setTimeout(resolve, 300));
        yield token;
      }
    },
  });
}
```

When used with [service](./service) class, the iterable can be delegated with `yield*` syntax:

```ts filename="src/modules/stream/StreamController.ts"
import { prefix, post, type VovkIteration } from 'vovk';
import StreamService from './StreamService';

@prefix('stream')
export default class StreamController {
  @post('completions')
  static getJSONLines = withZod({
    // ...
    iteration: z.object({
      message: z.string(),
    }),
    async *handle() {
      yield* StreamService.getJSONLines();
    },
  });
}
```

```ts filename="src/modules/stream/StreamService.ts"
import type { VovkIteration } from 'vovk';
import type { StreamController } from './StreamController';

export default class StreamService {
  static async *getJSONLines() {
    const tokens: VovkIteration<typeof StreamController.getJSONLines>[] = [
      { message: 'Hello,' },
      { message: ' World' },
      { message: ' from' },
      { message: ' Stream' },
      { message: '!' },
    ];

    for (const token of tokens) {
      await new Promise((resolve) => setTimeout(resolve, 300));
      yield token;
    }
  }
}
```


On the client side, the JSONLines output can be consumed using disposable async iterators, allowing to process each line as it arrives:

```ts
import { StreamRPC } from 'vovk-client';

using stream = await StreamRPC.getJSONLines();

for await (const { message } of stream) {
  console.log('Received message:', message);
}
```

<a name="jsonlinesresponse" />
## `JSONLinesResponse` class

If generators aren't sutable for JSON streaming at a particular case, you can use `JSONLinesResponse` class inherited from `Response` class that uses `TransformStream#readable` as response body.

It's a lower-level API that is used behind the scenes to implement generator logic described above.

A service method at this case is implemented as a regular function that accepts `JSONLinesResponse` instance as a pointer to send messages manually.

There is what the streaming service might look like:

```ts filename="src/modules/stream/StreamService.ts"
import type { JSONLinesResponse } from 'vovk';

export type Token = { message: string };

export default class StreamService {
  static async streamTokens(resp: JSONLinesResponse<Token>) {
    const tokens: Token[] = [{ message: 'Hello,' }, { message: ' World' }, { message: '!' }];

    for (const token of tokens) {
      await new Promise((resolve) => setTimeout(resolve, 300));
      resp.send(token);
    }

    resp.close();
  }
}
```

As you can see tokens are sent using `JSONLinesResponse#send` method and, when the stream is completed, it needs to be closed with `JSONLinesResponse#close`.

The controller class returns an instance of `JSONLinesResponse` and the streaming is performed a floating Promise above the `return` statement.

```ts
import { prefix, get, JSONLinesResponse, type VovkRequest } from 'vovk';
import StreamService, { type Token } from './StreamService';

@prefix('stream')
export default class StreamController {
  @get('tokens')
  static async streamTokens() {
    const resp = new JSONLinesResponse<Token>();

    void StreamService.streamTokens(resp);

    return resp;
  }
}
```

`JSONLinesResponse` class also provides `throw` method that safely closes the stream and makes the client to re-throw the received error.

```ts
await resp.throw(new Error('Stream error'));
```
{
/* import { Tabs, Callout } from 'nextra/components';
import LiveStreamExample from '../../../live-examples/LiveStreamExample';
import JSONLinesResponseObjectController from '../../../downloaded-examples/stream-response-object/StreamResponseObjectController.mdx';
import StreamService from '../../../downloaded-examples/stream-response-object/StreamService.mdx';
import StreamExample from '../../../downloaded-examples/stream-response-object/StreamExample.mdx';
import LiveJSONLinesResponseExample from '../../../live-examples/LiveStreamResponseExample';
import OpenAiController from '../../../downloaded-examples/openai/OpenAiController.mdx';
import OpenAiExample from '../../../downloaded-examples/openai/OpenAiExample.mdx';
import LiveOpenAiExample from '../../../live-examples/LiveOpenAiExample';

TODO: application/jsonl

# JSON streaming

Quick demo:

<div className="doc-live-example">
  <LiveStreamExample />
</div>

[Source code](https://vovk-examples.vercel.app/stream)

## Async iterators

Controller methods can implement generators that use `*` syntax and utilise `yield` keyword instead of the regular `return`.

```ts filename="src/modules/stream/StreamController.ts"
import { get, prefix } from 'vovk';

type Token = { message: string };

@prefix('stream')
export default class StreamController {
  @get('tokens')
  static async *streamTokens() {
    const tokens: Token[] = [{ message: 'Hello,' }, { message: ' World' }, { message: '!' }];

    for (const token of tokens) {
      await new Promise((resolve) => setTimeout(resolve, 300));
      yield token;
    }
  }
}
```

## Validation

TODO

## Using with service class

In order to refactor this code and utilise [service class](/controller/service) for code splitting, you can move the streaming logic to `StreamService` static class.

```ts filename="src/modules/stream/StreamService.ts"
type Token = { message: string };

export default class StreamService {
  static async *streamTokens() {
    const tokens: Token[] = [{ message: 'Hello,' }, { message: ' World' }, { message: '!' }];

    for (const token of tokens) {
      await new Promise((resolve) => setTimeout(resolve, 300));
      yield token;
    }
  }
}
```

At the controller use `yield*` syntax to delegate iterable returned from `StreamService.streamTokens`.

```ts filename="src/modules/stream/StreamController.ts"
import { get, prefix } from 'vovk';
import StreamService from './StreamService';

@prefix('stream')
export default class StreamController {
  @get('tokens')
  static async *streamTokens() {
    yield* StreamService.streamTokens();
  }
}
```

## Handling on the client

JSON streaming endpoints (including usage of lower-level `JSONLinesResponse` class described below) generate client methods that return disposable/async-disposable async generators.

```ts
import { StreamRPC } from 'vovk-client';

async function stream() {
  using stream = await StreamRPC.streamTokens();

  for await (const token of stream) {
    console.log(token);
  }
}
```

You can also use `await using` syntax to dispose the stream asynchronously.

```ts
// ...
await using stream = await StreamRPC.streamTokens();
```

## `JSONLinesResponse` class

Quick demo:

<div className="doc-live-example">
  <LiveJSONLinesResponseExample />
</div>

[Source code](https://vovk-examples.vercel.app/stream-response-object)

If generators aren't sutable for JSON streaming at a particular case, you can use `JSONLinesResponse` class inherited from `Response` class that uses `TransformStream#readable` as response body.
It's a lower-level API that is used behind the scenes to implement generator logic described above.
A service method at this case is implemented as a regular function that accepts `JSONLinesResponse` instance as a pointer to send messages manually.

There is what the streaming service might look like:

```ts filename="src/modules/stream/StreamService.ts"
import type { JSONLinesResponse } from 'vovk';

export type Token = { message: string };

export default class StreamService {
  static async streamTokens(resp: JSONLinesResponse<Token>) {
    const tokens: Token[] = [{ message: 'Hello,' }, { message: ' World' }, { message: '!' }];

    for (const token of tokens) {
      await new Promise((resolve) => setTimeout(resolve, 300));
      resp.send(token);
    }

    resp.close();
  }
}
```

As you can see tokens are sent using `JSONLinesResponse#send` method and, when the stream is completed, it needs to be closed with `JSONLinesResponse#close`.

The controller class returns an instance of `JSONLinesResponse` and the streaming is performed a floating Promise above the `return` statement.

```ts
import { prefix, get, JSONLinesResponse, type VovkRequest } from 'vovk';
import StreamService, { type Token } from './StreamService';

@prefix('stream')
export default class StreamController {
  @get('tokens')
  static async streamTokens() {
    const resp = new JSONLinesResponse<Token>();

    void StreamService.streamTokens(resp);

    return resp;
  }
}
```

`JSONLinesResponse` class also provides `throw` method that safely closes the stream and makes the client to re-throw the received error.

```ts
await resp.throw(new Error('Stream error'));
```

## How it works

The `JSONLinesResponse` class TODO

## OpenAI chat live example

<div className="doc-live-example">
  <LiveOpenAiExample />
</div>

View full code for this example on the [examples website](https://vovk-examples.vercel.app/openai).

`createChatCompletion` generator delegates the async iterable returned from `openai.chat.completions.create`
and the component utilises `using` keyword in order to close the stream safely in case of an interruption, iterating the messages using `await for` syntax.

```ts
import { type VovkRequest, post, prefix } from 'vovk';
import OpenAI from 'openai';

@prefix('openai')
export default class OpenAiController {
  private static openai = new OpenAI();

  @post('chat')
  static async *createChatCompletion(
    req: VovkRequest<{ messages: OpenAI.Chat.Completions.ChatCompletionMessageParam[] }>
  ) {
    const { messages } = await req.json();
    yield* await this.openai.chat.completions.create({
      messages,
      model: 'gpt-4o-mini',
      stream: true,
    });
  }
}
```

Usage on client side:

```ts
import { OpenAiRPC } from 'vovk-client';

// ...

// you can use "await using" suntax as well
using completion = await OpenAiRPC.createChatCompletion({
  body: { messages: [...messages, userMessage] },
});

for await (const chunk of completion) {
  // ...
}
```
*/}